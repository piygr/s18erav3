{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch transformers accelerate bitsandbytes peft trl datasets wandb\n!pip install datasets pandas treelib","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python -m bitsandbytes","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nfrom collections import defaultdict\nimport pandas as pd\nfrom datasets import load_dataset\n\n# Load dataset\ndataset = load_dataset(\"OpenAssistant/oasst1\", split=\"train\")\n\n# Convert to Pandas for easy manipulation\ndf = dataset.to_pandas()\n\n# Filter for English conversations\ndf = df[df[\"lang\"] == \"en\"]\n\n# Sort messages by conversation tree and index\ndf = df.sort_values(by=[\"message_tree_id\"])\ndf = df.sort_index()\n\n# Group by conversation trees\nconversation_trees = defaultdict(list)\nfor _, row in df.iterrows():\n    conversation_trees[row[\"message_tree_id\"]].append(row)\n\n# Function to extract multi-turn conversations\ndef process_conversations(conversation_list, output_full_tree=True):\n    formatted_data = []\n    \n    # Maintain context\n    context = \"\"\n    response = \"\"  # ✅ Define response outside the loop to avoid scope issues\n\n    for i, message in enumerate(conversation_list):\n        if message[\"role\"] == \"prompter\":  # User's message\n            context += f\"\\n\\n### User:\\n{message['text']}\"\n            response = \"\"  # Reset response for the new user prompt\n            \n            \n        elif message[\"role\"] == \"assistant\":\n            if not response:\n                response = message[\"text\"]  # ✅ First response in thread\n\n            if output_full_tree:\n                # Store the structured prompt-response pair\n                formatted_data.append({\"instruction\": context.strip(), \"response\": response})\n                \n                # Append response to context for next turns\n                context += f\"\\n\\n### Assistant:\\n{response}\"\n\n            else:\n                if i == 1:\n                    # Store the structured prompt-response pair\n                    formatted_data.append({\"instruction\": context.strip(), \"response\": response})\n                \n                break\n            \n        #print(i, context)\n    return formatted_data\n\n# Apply processing to all conversation trees\nfinal_data = []\nfor conversation in conversation_trees.values():\n    final_data.extend(process_conversations(conversation, output_full_tree=False))\n    #print(conversation)\n    #break\n\n# Save the processed dataset\nwith open(\"oasst1_multi_turn_phi2.json\", \"w\") as f:\n    json.dump(final_data, f, indent=4)\n\n#df.sample(1).transpose().to_dict()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T07:04:22.098990Z","iopub.execute_input":"2025-03-08T07:04:22.099363Z","iopub.status.idle":"2025-03-08T07:04:26.345945Z","shell.execute_reply.started":"2025-03-08T07:04:22.099326Z","shell.execute_reply":"2025-03-08T07:04:26.344933Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from datasets import load_dataset\n\n# Load JSON dataset\ndataset = load_dataset(\"json\", data_files=\"oasst1_multi_turn_phi2.json\")\n\n# Load Phi-2 tokenizer\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\")\ntokenizer.pad_token = tokenizer.eos_token\n\n# Tokenization function\ndef tokenize_function(examples):\n    # Ensure instructions and responses are processed as lists\n    instructions = examples[\"instruction\"]\n    responses = examples[\"response\"]\n\n    # Concatenate instruction and response for each example\n    texts = [f\"{inst}\\n\\n### Assistant:\\n{resp}\" for inst, resp in zip(instructions, responses)]\n\n    # Tokenize the batch of texts\n    return {'input_text': texts} #tokenizer(texts, padding=\"max_length\", truncation=True, max_length=1024)\n\n\n# Tokenize dataset\ntokenized_dataset = dataset.map(tokenize_function, batched=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T07:04:40.372200Z","iopub.execute_input":"2025-03-08T07:04:40.372574Z","iopub.status.idle":"2025-03-08T07:04:52.204228Z","shell.execute_reply.started":"2025-03-08T07:04:40.372539Z","shell.execute_reply":"2025-03-08T07:04:52.202712Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45155164a2554ea89b91944897621eb5"}},"metadata":{}},{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c80c2079212f4400918e4197c7820620"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/7.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62502bc0fcb64f98b891c22252c53a40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1096fa8f02a4db1a00b71b530235532"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cccdcd580b449419f88d7e7de3a3458"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23323d3b65464b7aa77bece5ce87a74f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07fbeedc7e0042b8ad6d08a2ba638b4a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7f4760023f4489fac70e52a5bee62a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3484 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1d40b44cf9d46cebfa841c3ee6624d9"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, BitsAndBytesConfig\nfrom peft import LoraConfig, get_peft_model\nimport torch\n\ndevice_map = {\"\": 0}\nmodel_name = \"microsoft/phi-2\"\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16,\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config=bnb_config,\n    trust_remote_code=True,\n    device_map=device_map\n)\nmodel.config.use_cache = False\nprint(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T07:04:55.926577Z","iopub.execute_input":"2025-03-08T07:04:55.927056Z","iopub.status.idle":"2025-03-08T07:05:41.214697Z","shell.execute_reply.started":"2025-03-08T07:04:55.927019Z","shell.execute_reply":"2025-03-08T07:05:41.213689Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82815a6135034b69be6ce486717c5e88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/35.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ce25c61079e4b77b656c26ac6f45169"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a543bc7b994540ccaa033d27176cd932"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cdcf336babc46be9fb41679c6b66df1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac3f73602456495ebdbe37f764a0cd4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"864a4a34e41c420abf891849bb2cacc5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"279f70c1bdcb4697a32b2245dc60cff4"}},"metadata":{}},{"name":"stdout","text":"PhiForCausalLM(\n  (model): PhiModel(\n    (embed_tokens): Embedding(51200, 2560)\n    (embed_dropout): Dropout(p=0.0, inplace=False)\n    (layers): ModuleList(\n      (0-31): 32 x PhiDecoderLayer(\n        (self_attn): PhiSdpaAttention(\n          (q_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n          (k_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n          (v_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n          (dense): Linear4bit(in_features=2560, out_features=2560, bias=True)\n          (rotary_emb): PhiRotaryEmbedding()\n        )\n        (mlp): PhiMLP(\n          (activation_fn): NewGELUActivation()\n          (fc1): Linear4bit(in_features=2560, out_features=10240, bias=True)\n          (fc2): Linear4bit(in_features=10240, out_features=2560, bias=True)\n        )\n        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n        (resid_dropout): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n    (rotary_emb): PhiRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=2560, out_features=51200, bias=True)\n)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from peft import LoraConfig\n\nlora_alpha = 16\nlora_dropout = 0.1\nlora_r = 64\n\ntarget_modules = [\n        \"q_proj\",\n        \"k_proj\",\n        \"v_proj\",\n        \"dense\",\n        \"fc1\",\n        \"fc2\"\n]\n\npeft_config = LoraConfig(\n    lora_alpha=lora_alpha,\n    lora_dropout=lora_dropout,\n    r=lora_r,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=target_modules\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T07:05:41.216539Z","iopub.execute_input":"2025-03-08T07:05:41.217490Z","iopub.status.idle":"2025-03-08T07:05:41.223192Z","shell.execute_reply.started":"2025-03-08T07:05:41.217445Z","shell.execute_reply":"2025-03-08T07:05:41.221912Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from trl import SFTConfig\nimport time\n\noutput_dir = \"./results\"\nper_device_train_batch_size = 4\ngradient_accumulation_steps = 8\noptim = \"paged_adamw_32bit\"\nsave_steps = 100\nlogging_steps = 10\nlearning_rate = 2e-4\nmax_grad_norm = 0.3\nmax_steps = 500\nwarmup_ratio = 0.03\nlr_scheduler_type = \"constant\"\nrun_name = f\"phi2-qlora-run-{int(time.time())}\"\nmax_seq_length = 256\n\nsft_config = SFTConfig(\n    output_dir=output_dir,\n    per_device_train_batch_size=per_device_train_batch_size,\n    gradient_accumulation_steps=gradient_accumulation_steps,\n    optim=optim,\n    save_steps=save_steps,\n    logging_steps=logging_steps,\n    learning_rate=learning_rate,\n    fp16=True,\n    max_grad_norm=max_grad_norm,\n    max_steps=max_steps,\n    warmup_ratio=warmup_ratio,\n    group_by_length=True,\n    lr_scheduler_type=lr_scheduler_type,\n    dataset_text_field=\"input_text\",\n    max_seq_length=max_seq_length,\n    run_name=run_name,\n    report_to=\"none\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T07:05:41.225090Z","iopub.execute_input":"2025-03-08T07:05:41.225339Z","iopub.status.idle":"2025-03-08T07:05:43.733559Z","shell.execute_reply.started":"2025-03-08T07:05:41.225318Z","shell.execute_reply":"2025-03-08T07:05:43.732236Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from trl import SFTTrainer\n\nmax_seq_length = 256\n\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=tokenized_dataset['train'],\n    peft_config=peft_config,\n    processing_class=tokenizer,\n    args=sft_config,\n)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T07:05:43.734797Z","iopub.execute_input":"2025-03-08T07:05:43.735141Z","iopub.status.idle":"2025-03-08T09:05:21.134107Z","shell.execute_reply.started":"2025-03-08T07:05:43.735108Z","shell.execute_reply":"2025-03-08T09:05:21.133290Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Converting train dataset to ChatML:   0%|          | 0/3484 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01f39babf3bf43e3a789c51df459616e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Applying chat template to train dataset:   0%|          | 0/3484 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8ad2635f64244b98d4a54e9aa86d9c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset:   0%|          | 0/3484 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac3d759687674c0aa395422ebedd7277"}},"metadata":{}},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (2856 > 2048). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Truncating train dataset:   0%|          | 0/3484 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ec73d2617c647c1a740508a0277c6c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [500/500 1:59:05, Epoch 4/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>11.645900</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>12.338500</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>13.316600</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>11.051500</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>13.083700</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>12.553500</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>10.825500</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>13.694400</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>11.034800</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>11.296900</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>14.271200</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>10.675800</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>11.726500</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>12.573100</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>10.642000</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>13.521600</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>10.754300</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>10.840700</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>13.381500</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>10.501300</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>11.764300</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>12.672600</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>10.703900</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>12.568900</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>10.906300</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>10.095100</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>12.698400</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>10.411600</td>\n    </tr>\n    <tr>\n      <td>290</td>\n      <td>11.194900</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>11.912900</td>\n    </tr>\n    <tr>\n      <td>310</td>\n      <td>10.226900</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>12.264100</td>\n    </tr>\n    <tr>\n      <td>330</td>\n      <td>12.110400</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>9.862900</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>12.034300</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>10.009800</td>\n    </tr>\n    <tr>\n      <td>370</td>\n      <td>10.557400</td>\n    </tr>\n    <tr>\n      <td>380</td>\n      <td>11.746800</td>\n    </tr>\n    <tr>\n      <td>390</td>\n      <td>9.722100</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>11.161100</td>\n    </tr>\n    <tr>\n      <td>410</td>\n      <td>11.354700</td>\n    </tr>\n    <tr>\n      <td>420</td>\n      <td>9.794900</td>\n    </tr>\n    <tr>\n      <td>430</td>\n      <td>12.005000</td>\n    </tr>\n    <tr>\n      <td>440</td>\n      <td>10.141300</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>10.041100</td>\n    </tr>\n    <tr>\n      <td>460</td>\n      <td>11.348400</td>\n    </tr>\n    <tr>\n      <td>470</td>\n      <td>9.566500</td>\n    </tr>\n    <tr>\n      <td>480</td>\n      <td>10.576000</td>\n    </tr>\n    <tr>\n      <td>490</td>\n      <td>10.504600</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>9.536300</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=500, training_loss=11.38444842529297, metrics={'train_runtime': 7163.9105, 'train_samples_per_second': 2.233, 'train_steps_per_second': 0.07, 'total_flos': 5.233902520516608e+16, 'train_loss': 11.38444842529297})"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nmodel_name = \"microsoft/phi-2\"\ndevice_map = {\"\": 0}\n\n# Reload model in FP16 and merge it with LoRA weights\nbase_model = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    low_cpu_mem_usage=True,\n    return_dict=True,\n    torch_dtype=torch.float16,\n    trust_remote_code=True,\n    device_map=device_map,\n)\n\nfrom peft import PeftModel\nnew_model = \"/kaggle/working/results/checkpoint-500\"\nmodel = PeftModel.from_pretrained(base_model, new_model)\nmodel = model.merge_and_unload()\n\n# Reload tokenizer to save it\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T09:09:16.887128Z","iopub.execute_input":"2025-03-08T09:09:16.887451Z","iopub.status.idle":"2025-03-08T09:09:23.786039Z","shell.execute_reply.started":"2025-03-08T09:09:16.887426Z","shell.execute_reply":"2025-03-08T09:09:23.785153Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07e5754275694de5ba735242b9a1c3f6"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"from transformers import pipeline\n\nprompt = \"\\n\\n### User:\\nWhat was the role of indian revolutionaries in indian independence movement ?\\n\\n### Assistant:\\n\"  # change to your desired prompt\ngen = pipeline('text-generation', model=model, tokenizer=tokenizer, max_length=500)\nresult = gen(prompt)\nprint(result[0]['generated_text'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T09:16:13.362333Z","iopub.execute_input":"2025-03-08T09:16:13.362733Z","iopub.status.idle":"2025-03-08T09:16:23.826698Z","shell.execute_reply.started":"2025-03-08T09:16:13.362700Z","shell.execute_reply":"2025-03-08T09:16:23.825780Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"\n\n### User:\nWhat was the role of indian revolutionaries in indian independence movement ?\n\n### Assistant:\nIndian revolutionaries played a significant role in the Indian independence movement. They were individuals who used various means, including violence, to fight against British colonial rule and to promote the idea of an independent India.\n\nThe Indian revolutionaries were inspired by the ideas of nationalism and freedom that were spreading throughout the world at the time. They were influenced by the writings of Indian leaders such as Mahatma Gandhi, Jawaharlal Nehru, and Subhash Chandra Bose, who advocated for non-violent resistance and armed struggle against British rule.\n\nThe revolutionaries used various methods to carry out their activities, including assassinations of British officials, bombings, and sabotage. Some of the most famous Indian revolutionaries include Bhagat Singh, Sukhdev Thapar, and Rash Behari Bose.\n\nThe revolutionaries were also involved in the formation of various organizations, such as the Hindustan Socialist Republican Association (HSRA) and the Ghadar Party, which aimed to promote the idea of an independent India and to carry out armed struggle against British rule.\n\nThe role of Indian revolutionaries in the Indian independence movement was significant, as they helped to raise awareness about the need for independence and to mobilize people against British rule. Their actions inspired many others to join the fight for independence, and their legacy continues to be remembered today.\n\nIn conclusion, Indian revolutionaries played a crucial role in the Indian independence movement by using various means to fight against British colonial rule and to promote the idea of an independent India. Their actions continue to inspire people today, and their legacy is an important part of India's history.\n\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"prompt = '''### User:\\nExplain CNN to a five year old.\\n\\n### Assistant:\\nA Convolutional Neural Network (CNN) is like a special kind of computer brain that can look at pictures and understand what they are about. It's like a big puzzle solver that can find patterns and shapes in pictures.\\nImagine you have a picture of a cat. A CNN can look at each tiny piece of the picture, called a pixel, and figure out what color it is. Then it can look at the colors of the pixels around it and figure out if they make up the cat's fur or its eyes. It can do this over and over again, looking at different parts of the picture, until it understands the whole picture and knows it's a cat.\\nCNNs are used in lots of different things, like helping robots see and understand the world around them, or helping doctors look at X-rays and find problems in our bodies. They're really smart and can do lots of things that humans can do, but even better!\\nSo, in short, a CNN is a special kind of computer brain that can look at pictures and understand what they are about by finding patterns and shapes in them. It's like a big puzzle solver that can do things that humans can do, but even better!\\nI hope that helps you understand what a CNN is! Let me know if you have any other questions.\\n\\n### User:\\nWhat does it mean by convolution here?\\n\\n### Assistant:\\n'''  # change to your desired prompt\ngen = pipeline('text-generation', model=model, tokenizer=tokenizer, max_length=500)\nresult = gen(prompt)\nprint(result[0]['generated_text'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T09:45:25.287461Z","iopub.execute_input":"2025-03-08T09:45:25.287874Z","iopub.status.idle":"2025-03-08T09:45:31.669659Z","shell.execute_reply.started":"2025-03-08T09:45:25.287842Z","shell.execute_reply":"2025-03-08T09:45:31.668720Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"### User:\nExplain CNN to a five year old.\n\n### Assistant:\nA Convolutional Neural Network (CNN) is like a special kind of computer brain that can look at pictures and understand what they are about. It's like a big puzzle solver that can find patterns and shapes in pictures.\nImagine you have a picture of a cat. A CNN can look at each tiny piece of the picture, called a pixel, and figure out what color it is. Then it can look at the colors of the pixels around it and figure out if they make up the cat's fur or its eyes. It can do this over and over again, looking at different parts of the picture, until it understands the whole picture and knows it's a cat.\nCNNs are used in lots of different things, like helping robots see and understand the world around them, or helping doctors look at X-rays and find problems in our bodies. They're really smart and can do lots of things that humans can do, but even better!\nSo, in short, a CNN is a special kind of computer brain that can look at pictures and understand what they are about by finding patterns and shapes in them. It's like a big puzzle solver that can do things that humans can do, but even better!\nI hope that helps you understand what a CNN is! Let me know if you have any other questions.\n\n### User:\nWhat does it mean by convolution here?\n\n### Assistant:\nConvolution is a special kind of math that a CNN uses to look at pictures. It's like a way of sliding a small piece of the picture, called a filter, over the whole picture and looking at how the colors in the filter match up with the colors in the picture.\nThe filter is like a little puzzle piece that the CNN uses to find patterns and shapes in the picture. It's made up of lots of tiny dots, each with a different color. When the CNN slides the filter over the picture, it looks at how the colors in the filter match up with the colors in the picture. If the colors in the filter match up well with the colors in the picture, it means that the filter is looking at a part of the picture that is similar to the part of the picture that the filter is covering.\nThe CNN does this over and over again, sliding the filter over different parts of the picture, until it\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"'''### User:\\nExplain CNN to a five year old.\\n\\n### Assistant:\\nA Convolutional Neural Network (CNN) is like a special kind of computer brain that can look at pictures and understand what they are about. It's like a big puzzle solver that can find patterns and shapes in pictures.\\nImagine you have a picture of a cat. A CNN can look at each tiny piece of the picture, called a pixel, and figure out what color it is. Then it can look at the colors of the pixels around it and figure out if they make up the cat's fur or its eyes. It can do this over and over again, looking at different parts of the picture, until it understands the whole picture and knows it's a cat.\\nCNNs are used in lots of different things, like helping robots see and understand the world around them, or helping doctors look at X-rays and find problems in our bodies. They're really smart and can do lots of things that humans can do, but even better!\\nSo, in short, a CNN is a special kind of computer brain that can look at pictures and understand what they are about by finding patterns and shapes in them. It's like a big puzzle solver that can do things that humans can do, but even better!\\nI hope that helps you understand what a CNN is! Let me know if you have any other questions.\\n\\n### User:\\nWhat does it mean by convolution here?'''","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import torch\n\nimport gc\n\ngc.collect()  # ✅ Python garbage collection\ntorch.cuda.empty_cache()\n!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T06:36:56.420179Z","iopub.execute_input":"2025-03-08T06:36:56.420494Z","iopub.status.idle":"2025-03-08T06:36:57.213835Z","shell.execute_reply.started":"2025-03-08T06:36:56.420469Z","shell.execute_reply":"2025-03-08T06:36:57.212933Z"}},"outputs":[{"name":"stdout","text":"Sat Mar  8 06:36:57 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   36C    P0             32W /  250W |   16191MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":37}]}